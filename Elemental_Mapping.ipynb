{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn \n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Elemental_Mapping.datasets.Pixel2PixelDataset import Pixel2PixelDataset\n",
    "\n",
    "images = ['gogo', 'dionisios', 'fanourios', 'minos', 'odigitria']\n",
    "test_image = 'saintjohn'\n",
    "\n",
    "band_range = range(0, 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Pixel2PixelDataset(\n",
    "    '/home/igeor/MSC-THESIS/data/h5',\n",
    "    image_names=images, \n",
    "    sample_step = 10, \n",
    "    device='cuda', \n",
    "    band_range=(band_range.start, band_range.stop), \n",
    "    target_elems=['S_K','K_K','Ca_K','Cr_K','Mn_K','Fe_K','Cu_K','Zn_K','Sr_K','Au_L','Hg_L','Pb_L'])\n",
    "\n",
    "# Split dataset into training and validation\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully Connected Network\n",
    "from Elemental_Mapping.models.FullyConnectedModel import FullyConnectedModel \n",
    "from spec_db import pure_elements\n",
    "from Elemental_Mapping.models.PriorLayer import PriorLayer \n",
    "\n",
    "# set as w the values of keys of pure_elements\n",
    "w = torch.cat([pure_spectrum.unsqueeze(0) for pure_spectrum in pure_elements.values()], dim=0)\n",
    "prior_layer = PriorLayer(\n",
    "    w, s=None, bias=False, apply_sum=True, requres_grad=False, device='cuda') \n",
    "\n",
    "fcn = FullyConnectedModel(\n",
    "    in_features=4096, \n",
    "    out_features=12, \n",
    "    hidden_dims=[512, 64, 64], \n",
    "    prior_layer=prior_layer,\n",
    "    dropout=0.0\n",
    ").to(device)\n",
    "\n",
    "fcn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Elemental_Mapping.loss_functions.AdaptiveL1Loss import AdaptiveL1Loss\n",
    "\n",
    "# Loss Function\n",
    "train_criterion = AdaptiveL1Loss()\n",
    "# Adam Optimizer\n",
    "fcn_optimizer = torch.optim.Adam(fcn.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2000\n",
    "eval_n_epochs = 2\n",
    "min_val_loss = np.inf\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = fcn.train(train_loader, fcn_optimizer, train_criterion, epochs=1, device='cuda')\n",
    "    if epoch % eval_n_epochs == 0:\n",
    "        eval_loss, _ = fcn.eval(val_loader, train_criterion, device='cuda')\n",
    "    print(f'Epoch: {epoch}, Train Loss: {train_loss} Eval Loss: {eval_loss}')\n",
    "    if eval_loss < min_val_loss:\n",
    "        min_val_loss = eval_loss\n",
    "        torch.save(fcn.state_dict(), f'./results/Elemental_Mapping/new models/fcn_testOdigitria_v3.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Pixel2PixelDataset(\n",
    "    '/home/igeor/MSC-THESIS/data/h5',\n",
    "    image_names=[test_image], \n",
    "    sample_step = 1, \n",
    "    device='cuda', \n",
    "    band_range=(band_range.start, band_range.stop), \n",
    "    target_elems=['S_K','K_K','Ca_K','Cr_K','Mn_K','Fe_K','Cu_K','Zn_K','Sr_K','Au_L','Hg_L','Pb_L'])\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open target image file (elemental_maps)\n",
    "df = pd.read_csv(f'/home/igeor/MSC-THESIS/data/h5/elem_maps/{test_image}.dat' , sep='  ', engine='python')\n",
    "width, height = df['row'].iloc[-1] + 1, df['column'].iloc[-1] + 1\n",
    "y_real = np.array(df[test_dataset.target_elems])\n",
    "y_real = y_real.reshape((width, height, len(test_dataset.target_elems)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fcn state_dict\n",
    "fcn.load_state_dict(torch.load(f'./results/Elemental_Mapping/models/FCNplus_testSaintJohn.pt'))\n",
    "\n",
    "_, y_pred = fcn.eval(test_loader, torch.nn.L1Loss(), device='cuda')\n",
    "\n",
    "fcnplus_y_pred = y_pred.reshape((width, height, len(test_dataset.target_elems))).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1d Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Elemental_Mapping.datasets.Pixel2PixelDataset import Pixel2PixelDataset\n",
    "\n",
    "images = ['gogo', 'dionisios', 'fanourios', 'minos', 'odigitria']\n",
    "test_image = 'saintjohn'\n",
    "band_range = range(0, 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Pixel2PixelDataset(\n",
    "    '/home/igeor/MSC-THESIS/data/h5',\n",
    "    image_names=images, \n",
    "    sample_step = 10, \n",
    "    device='cuda', \n",
    "    band_range=(band_range.start, band_range.stop), \n",
    "    target_elems=['S_K','K_K','Ca_K','Cr_K','Mn_K','Fe_K','Cu_K','Zn_K','Sr_K','Au_L','Hg_L','Pb_L'])\n",
    "\n",
    "# Split dataset into training and validation\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully Connected Network\n",
    "from Elemental_Mapping.models.Conv1DModel import Conv1DModel \n",
    "from spec_db import pure_elements\n",
    "from Elemental_Mapping.models.PriorLayer import PriorLayer \n",
    "\n",
    "# Set as w the values of keys of pure_elements\n",
    "w = torch.cat([pure_spectrum.unsqueeze(0) for pure_spectrum in pure_elements.values()], dim=0)\n",
    "# Initialize the PriorLayer\n",
    "prior_layer = PriorLayer(w, s=None, bias=False, apply_sum=False, requres_grad=False, device='cuda') \n",
    "\n",
    "cnn1d = Conv1DModel(in_features=4096, hidden_dims=[64, 64, 64, 64, 128], out_features=12, \n",
    "    prior_layer=prior_layer, iis=True, flatten_dims=512, dropout=0.0).to(device)\n",
    "\n",
    "print(cnn1d.alias)\n",
    "cnn1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Elemental_Mapping.loss_functions.AdaptiveL1Loss import AdaptiveL1Loss\n",
    "\n",
    "# Loss Function\n",
    "train_criterion = AdaptiveL1Loss()\n",
    "# Adam Optimizer\n",
    "cnn1d_optimizer = torch.optim.Adam(cnn1d.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('./results/Elemental_Mapping/CNN1Dplus_testSaintJohn.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['epoch', 'train_loss', 'val_loss'])\n",
    "\n",
    "\n",
    "n_epochs = 1500\n",
    "eval_n_epochs = 5\n",
    "\n",
    "min_val_loss = np.inf\n",
    "for epoch in range(0, n_epochs):\n",
    "    train_loss = cnn1d.train(train_loader, cnn1d_optimizer, train_criterion, epochs=1, device='cuda')\n",
    "    # Evaluate on validation set every eval_n_epochs\n",
    "    if epoch % eval_n_epochs == 0:\n",
    "        eval_loss, _ = cnn1d.eval(val_loader, train_criterion, device='cuda')\n",
    "        \n",
    "    # Save model if eval_loss is the lowest so far\n",
    "    if eval_loss < min_val_loss:\n",
    "        min_val_loss = eval_loss\n",
    "        torch.save(cnn1d.state_dict(), f'./results/Elemental_Mapping/{cnn1d.alias}.pt')\n",
    "    \n",
    "    # Store the training and validation losses for each epoch in a csv file\n",
    "    with open('./results/Elemental_Mapping/CNN1Dplus_testSaintJohn.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([epoch, train_loss, eval_loss])\n",
    "\n",
    "    # Print train and eval loss\n",
    "    print(f'Epoch: {epoch}, Train Loss: {round(train_loss, 4)} Eval Loss: {round(eval_loss, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_range = range(0, 4096)\n",
    "\n",
    "test_dataset = Pixel2PixelDataset(\n",
    "    '/home/igeor/MSC-THESIS/data/h5',\n",
    "    image_names = [test_image], \n",
    "    sample_step = 1, \n",
    "    device='cuda', \n",
    "    band_range=(band_range.start, band_range.stop), \n",
    "    target_elems=['S_K','K_K','Ca_K','Cr_K','Mn_K','Fe_K','Cu_K','Zn_K','Sr_K','Au_L','Hg_L','Pb_L'])\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open target image file (elemental_maps)\n",
    "df = pd.read_csv(f'/home/igeor/MSC-THESIS/data/h5/elem_maps/{test_image}.dat' , sep='  ', engine='python')\n",
    "width, height = df['row'].iloc[-1] + 1, df['column'].iloc[-1] + 1\n",
    "y_real = np.array(df[test_dataset.target_elems])\n",
    "y_real = y_real.reshape((width, height, len(test_dataset.target_elems)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cnn1d state_dict\n",
    "cnn1d.load_state_dict(torch.load(f'./results/Elemental_Mapping/models/CNN1Dplus_testSaintJohn.pt'))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "_, y_pred = cnn1d.eval(test_loader, torch.nn.L1Loss(), device='cuda')\n",
    "\n",
    "y_pred = y_pred.reshape((width, height, len(test_dataset.target_elems))).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the pred and real (12) image in a 2x12 grid\n",
    "fix, axs = plt.subplots(2, len(test_dataset.target_elems), figsize=(20, 10))\n",
    "for i in range(len(test_dataset.target_elems)):\n",
    "\n",
    "    axs[0, i].imshow(y_real[:,:,i])\n",
    "    axs[0, i].set_title(test_dataset.target_elems[i])\n",
    "    axs[0, i].set_xticks([]); axs[0, i].set_yticks([])\n",
    "    axs[0, 0].set_ylabel('GT')\n",
    "\n",
    "    axs[1, i].imshow(y_pred[:,:,i])\n",
    "    axs[1, 0].set_ylabel('Pred')\n",
    "    axs[1, i].set_xticks([]); axs[1, i].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f'./results/Elemental_Mapping/{cnn1d.alias}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_eval(y_real, y_pred):\n",
    "    # Initialize an empty numpy array of shape (w, h, 3)\n",
    "    out_image = np.zeros((width, height, 3))\n",
    "    \n",
    "    # Compute the z-score of y_pred and y_real\n",
    "    zscore = (np.abs(y_pred[:,:,i] - y_real[:,:,i])) / np.sqrt(y_real[:,:,i] + 1)\n",
    "\n",
    "    # Find the indices where zscore is between 0 and 1 \n",
    "    # and set the corresponding pixels to white color\n",
    "    z0to1 = np.logical_and(zscore >= 0, zscore < 1) \n",
    "    num_0to1 = z0to1.sum()\n",
    "    pxls_x, pxls_y = np.where(z0to1 == True)\n",
    "    out_image[pxls_x, pxls_y, :] = [1, 1, 1]\n",
    "\n",
    "    # Find the indices where zscore is between 1 and 2 \n",
    "    # and set the corresponding pixels to orange color\n",
    "    z1to2 = np.logical_and(zscore >= 1, zscore < 2)\n",
    "    num_1to2 = z1to2.sum()\n",
    "    pxls_x, pxls_y = np.where(z1to2 == True)\n",
    "    out_image[pxls_x, pxls_y, :] = [1, 0.5, 0]\n",
    "\n",
    "    # Find the indices where zscore is between 2 and 3\n",
    "    # and set the corresponding pixels to red color\n",
    "    z2to3 = np.logical_and(zscore >= 2, zscore < 3)\n",
    "    num_2to3 = z2to3.sum()\n",
    "    pxls_x, pxls_y = np.where(z2to3 == True)\n",
    "    out_image[pxls_x, pxls_y, :] = [1, 0, 0]\n",
    "\n",
    "    # Find the indices where zscore is greater than 3\n",
    "    # and set the corresponding pixels to black color\n",
    "    z3toInf = zscore >= 3\n",
    "    num_3toInf = z3toInf.sum()\n",
    "    pxls_x, pxls_y = np.where(z3toInf == True)\n",
    "    out_image[pxls_x, pxls_y, :] = [0, 0, 0]\n",
    "\n",
    "    return out_image, num_0to1, num_1to2, num_2to3, num_3toInf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-score of y_pred and y_real\n",
    "zscore_per_elem = { elem: None for elem in test_dataset.target_elems }\n",
    "\n",
    "fig, axes = plt.subplots(2, 12, figsize=(20, 10))\n",
    "for i in range(len(test_dataset.target_elems)):\n",
    "    axes[0, i].imshow(y_real[:,:,i])\n",
    "    axes[0, i].set_title(test_dataset.target_elems[i])\n",
    "    axes[0, i].set_xticks([]); axes[0, i].set_yticks([])\n",
    "    axes[0, 0].set_ylabel('GT')\n",
    "\n",
    "for i in range(len(test_dataset.target_elems)):\n",
    "    out_image, num_0to1, num_1to2, num_2to3, num_3toInf = z_score_eval(y_real, y_pred)\n",
    "    axes[1, i].imshow(out_image)\n",
    "    axes[1, 0].set_ylabel('Pred')\n",
    "    axes[1, i].set_xticks([]); axes[1, i].set_yticks([])\n",
    "\n",
    "print(f'Percentage of pixels with zscore between 0 and 1: {num_0to1 / (width * height)}')\n",
    "print(f'Percentage of pixels with zscore between 1 and 2: {num_1to2 / (width * height) }')\n",
    "print(f'Percentage of pixels with zscore between 2 and 3: {num_2to3 / (width * height) }')\n",
    "print(f'Percentage of pixels with zscore greater than 3: {num_3toInf / (width * height) }')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "ssim_per_elem = { elem: 0.0 for elem in test_dataset.target_elems }\n",
    "\n",
    "for i in range(len(test_dataset.target_elems)):\n",
    "    if isinstance(y_pred, torch.Tensor): y_pred = y_pred.cpu().detach().numpy()\n",
    "    \n",
    "    ssim_score = ssim(y_real[:,:,i], y_pred[:,:,i], data_range=1.0)\n",
    "    ssim_per_elem[test_dataset.target_elems[i]] = ssim_score\n",
    "\n",
    "# compute the mean of ssim per element\n",
    "print(f'Mean SSIM per element: {np.mean(list(ssim_per_elem.values()))}')\n",
    "ssim_per_elem['total'] = ssim(y_real, y_pred, data_range=1.0)\n",
    "ssim_per_elem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the pearson correlation between the real and predicted y_real and y_pred\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "pearson_per_elem = { elem: 0.0 for elem in test_dataset.target_elems }\n",
    "for i in range(len(test_dataset.target_elems)):\n",
    "    pearson_score = pearsonr(y_real[:,:,i].flatten(), y_pred[:,:,i].flatten())[0]\n",
    "    if np.isnan(pearson_score): pearson_score = 0.0\n",
    "    pearson_per_elem[test_dataset.target_elems[i]] = pearson_score\n",
    "\n",
    "# compute the mean of pearson per element\n",
    "print(f'Mean Pearson per element: {np.mean(list(pearson_per_elem.values()))}')\n",
    "pearson_per_elem['total'] = pearsonr(y_real.flatten(), y_pred.flatten())[0]\n",
    "pearson_per_elem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_per_elem = { elem: 0.0 for elem in test_dataset.target_elems }\n",
    "\n",
    "for i in range(len(test_dataset.target_elems)):\n",
    "    y_pred_flat = y_pred[:,:,i].flatten()\n",
    "    y_real_flat = y_real[:,:,i].flatten()\n",
    "    slope_score = np.mean((y_pred_flat + 1) / (y_real_flat + 1))\n",
    "    if np.isnan(slope_score): slope_score = 0.0\n",
    "    slope_per_elem[test_dataset.target_elems[i]] = slope_score \n",
    "\n",
    "# compute the mean slope per element\n",
    "print(f'Mean slope per element: {np.mean(list(slope_per_elem.values()))}')\n",
    "slope_per_elem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
